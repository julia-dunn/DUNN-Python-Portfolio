{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 1: Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['The', 'quick', 'brown', 'fox', 'does', \"n't\", 'jump', 'over', 'the', 'lazy', 'dog', '.', 'Natural', 'Language', 'Processing', 'is', 'fascinating', '!']\n"
     ]
    }
   ],
   "source": [
    "import spacy # imports spacy dictionary\n",
    "nlp = spacy.load('en_core_web_sm') # establishes nlp function\n",
    "text = (\"The quick brown fox doesn't jump over the lazy dog. Natural Language Processing is fascinating!\") # creates the text (string)\n",
    "doc = nlp(text) # turns the string into understandable spacy object\n",
    "\n",
    "tokens_spacy = [token.text for token in doc] # creates a list of the tokens in the doc object\n",
    "print(tokens_spacy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The: Head = fox, Lemma: the, Morph: Definite=Def|PronType=Art\n",
      "quick: Head = fox, Lemma: quick, Morph: Degree=Pos\n",
      "brown: Head = fox, Lemma: brown, Morph: Degree=Pos\n",
      "fox: Head = jump, Lemma: fox, Morph: Number=Sing\n",
      "does: Head = jump, Lemma: do, Morph: Mood=Ind|Number=Sing|Person=3|Tense=Pres|VerbForm=Fin\n",
      "n't: Head = jump, Lemma: not, Morph: Polarity=Neg\n",
      "jump: Head = jump, Lemma: jump, Morph: VerbForm=Inf\n",
      "over: Head = jump, Lemma: over, Morph: \n",
      "the: Head = dog, Lemma: the, Morph: Definite=Def|PronType=Art\n",
      "lazy: Head = dog, Lemma: lazy, Morph: Degree=Pos\n",
      "dog: Head = over, Lemma: dog, Morph: Number=Sing\n",
      ".: Head = jump, Lemma: ., Morph: PunctType=Peri\n",
      "Natural: Head = Language, Lemma: Natural, Morph: Number=Sing\n",
      "Language: Head = Processing, Lemma: Language, Morph: Number=Sing\n",
      "Processing: Head = is, Lemma: processing, Morph: Number=Sing\n",
      "is: Head = is, Lemma: be, Morph: Mood=Ind|Number=Sing|Person=3|Tense=Pres|VerbForm=Fin\n",
      "fascinating: Head = is, Lemma: fascinating, Morph: Degree=Pos\n",
      "!: Head = is, Lemma: !, Morph: PunctType=Peri\n"
     ]
    }
   ],
   "source": [
    "for token in doc: \n",
    "    print(f\"{token.text}: Head = {token.head}, Lemma: {token.lemma_}, Morph: {token.morph}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SpaCy treats punctuation like periods and commas as their own individual tokens. Interestingly, with contractions such as the word \"doesn't,\" spaCy created a token for \"does\" and a token for \"n't.\"\n",
    "\n",
    "For the attribute \".text,\" the tokens are each simply converted to strings. The doc itself can also be converted into a string, but there is no unexpected behavior. With \".head\" there was interesting behavior regarding the punctuation, for both the period and the exclamation mark the head word was the verb of the sentence. The \".lemma_\" attribute once again had expected results and generally clarified why \"n't\" was a separate token from \"does,\" as it has its own individual base word which can be analyzed. Finally, \".morph\" provided information regarding the plurality, degree,tense, verb form, etc of each token. It interestingly did not provide any information for the word over, even though it did understand the punctuation tokens."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 2: Part of Speech Tagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The: Head = fox, Lemma: the, Morph: Definite=Def|PronType=Art, POS = DET, TAG = DT\n",
      "quick: Head = fox, Lemma: quick, Morph: Degree=Pos, POS = ADJ, TAG = JJ\n",
      "brown: Head = fox, Lemma: brown, Morph: Degree=Pos, POS = ADJ, TAG = JJ\n",
      "fox: Head = jump, Lemma: fox, Morph: Number=Sing, POS = NOUN, TAG = NN\n",
      "does: Head = jump, Lemma: do, Morph: Mood=Ind|Number=Sing|Person=3|Tense=Pres|VerbForm=Fin, POS = AUX, TAG = VBZ\n",
      "n't: Head = jump, Lemma: not, Morph: Polarity=Neg, POS = PART, TAG = RB\n",
      "jump: Head = jump, Lemma: jump, Morph: VerbForm=Inf, POS = VERB, TAG = VB\n",
      "over: Head = jump, Lemma: over, Morph: , POS = ADP, TAG = IN\n",
      "the: Head = dog, Lemma: the, Morph: Definite=Def|PronType=Art, POS = DET, TAG = DT\n",
      "lazy: Head = dog, Lemma: lazy, Morph: Degree=Pos, POS = ADJ, TAG = JJ\n",
      "dog: Head = over, Lemma: dog, Morph: Number=Sing, POS = NOUN, TAG = NN\n",
      ".: Head = jump, Lemma: ., Morph: PunctType=Peri, POS = PUNCT, TAG = .\n",
      "Natural: Head = Language, Lemma: Natural, Morph: Number=Sing, POS = PROPN, TAG = NNP\n",
      "Language: Head = Processing, Lemma: Language, Morph: Number=Sing, POS = PROPN, TAG = NNP\n",
      "Processing: Head = is, Lemma: processing, Morph: Number=Sing, POS = NOUN, TAG = NN\n",
      "is: Head = is, Lemma: be, Morph: Mood=Ind|Number=Sing|Person=3|Tense=Pres|VerbForm=Fin, POS = AUX, TAG = VBZ\n",
      "fascinating: Head = is, Lemma: fascinating, Morph: Degree=Pos, POS = ADJ, TAG = JJ\n",
      "!: Head = is, Lemma: !, Morph: PunctType=Peri, POS = PUNCT, TAG = .\n"
     ]
    }
   ],
   "source": [
    "for token in doc: \n",
    "    print(f\"{token.text}: Head = {token.head}, Lemma: {token.lemma_}, Morph: {token.morph}, POS = {token.pos_}, TAG = {token.tag_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The POS tag for quick is ADJ, indicating the word quick is used as an adjective. The tag itself is JJ, which is more specific and indicates that the word is an adjective determinator, and not a coordinating conjunction. \n",
    "\n",
    "The POS tag for jumps (lemma=jump) is VERB, which indicates that the word jumps is being used as a verb. The TAG uses the VB code to indicate the verb is being used in its base form. This is interesting because in fact jumps is being used as a 3rd person singular present which is denoted typically with VBZ.\n",
    "\n",
    "The POS tag for is (lemma=be) is AUX, which indicates that the word is an auxilary, meaning it is a verb that accompanies a main verb. This is also incorrect because the word \"is\" is indeed the main verb of the sentence. The TAG assigns \"is\" the tag VBZ which is accurately the third person singular present tense. \n",
    "\n",
    "POS tagging is useful for tasks like grammar checking or machine translation because it demonstrates what parts of the text the computer may be misunderstanding. Even though it has all the information, since words can be used in different contexts, it is valuable to see how the computer program is understanding the combination in a specific case. As demonstrated above, the POS tag for the word \"is\" was somewhat inaccurate or nonspecific, and similarly both the POS and TAG codes were not entirely accurate for the word \"jumps.\" This tagging informaiton provides insight as one might further analyze a text or implement more complicated programming, in case that analysis hinges on a nuanced understanding."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 3: Named Entity Recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Barack Obama: PERSON (People, including fictional)\n",
      "44th: ORDINAL (\"first\", \"second\", etc.)\n",
      "the United States: GPE (Countries, cities, states)\n",
      "Hawaii: GPE (Countries, cities, states)\n"
     ]
    }
   ],
   "source": [
    "text2 = (\"Barack Obama was the 44th President of the United States. He was born in Hawaii\")\n",
    "doc2 = nlp(text2)\n",
    "\n",
    "for ent in doc2.ents:\n",
    "    print(f\"{ent.text}: {ent.label_} ({spacy.explain(ent.label_)})\") # creates list of specific entitiies, (i.e. proper nouns, etc.) and what sort of entity they are according to the nlp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The entities recognized by spacy in this text include \"Barack Obama,\" \"44th,\" \"the United States\" and \"Hawaii.\" It was interesting that the word \"the\" was included in the entity \"the United States.\" Barack Obama is a person entity, and as described above this includes both real and fictional people. \"Hawaii\" is a GPE (geopolitical entity) entity, which includes countries, cities, and states.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 4: Experimentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Although: Head = is, Lemma: although, Morph: , POS = SCONJ, TAG = IN\n",
      "Julia: Head = is, Lemma: Julia, Morph: Number=Sing, POS = PROPN, TAG = NNP\n",
      "is: Head = feel, Lemma: be, Morph: Mood=Ind|Number=Sing|Person=3|Tense=Pres|VerbForm=Fin, POS = AUX, TAG = VBZ\n",
      "at: Head = least, Lemma: at, Morph: , POS = ADP, TAG = IN\n",
      "least: Head = is, Lemma: least, Morph: Degree=Sup, POS = ADJ, TAG = JJS\n",
      "': Head = is, Lemma: ', Morph: NumType=Card, POS = NUM, TAG = CD\n",
      "19: Head = year, Lemma: 19, Morph: NumType=Card, POS = NUM, TAG = CD\n",
      "year: Head = old, Lemma: year, Morph: Number=Sing, POS = NOUN, TAG = NN\n",
      "old: Head = is, Lemma: old, Morph: Degree=Pos, POS = ADJ, TAG = JJ\n",
      "': Head = is, Lemma: ', Morph: PunctSide=Fin|PunctType=Quot, POS = PUNCT, TAG = ''\n",
      ",: Head = feel, Lemma: ,, Morph: PunctType=Comm, POS = PUNCT, TAG = ,\n",
      "I: Head = feel, Lemma: I, Morph: Case=Nom|Number=Sing|Person=1|PronType=Prs, POS = PRON, TAG = PRP\n",
      "feel: Head = feel, Lemma: feel, Morph: Tense=Pres|VerbForm=Fin, POS = VERB, TAG = VBP\n",
      "like: Head = lived, Lemma: like, Morph: , POS = SCONJ, TAG = IN\n",
      "she: Head = lived, Lemma: she, Morph: Case=Nom|Gender=Fem|Number=Sing|Person=3|PronType=Prs, POS = PRON, TAG = PRP\n",
      "has: Head = lived, Lemma: have, Morph: Mood=Ind|Number=Sing|Person=3|Tense=Pres|VerbForm=Fin, POS = AUX, TAG = VBZ\n",
      "lived: Head = feel, Lemma: live, Morph: Aspect=Perf|Tense=Past|VerbForm=Part, POS = VERB, TAG = VBN\n",
      "a: Head = million, Lemma: a, Morph: Definite=Ind|PronType=Art, POS = DET, TAG = DT\n",
      "million: Head = lives, Lemma: million, Morph: NumType=Card, POS = NUM, TAG = CD\n",
      "lives: Head = lived, Lemma: life, Morph: Number=Plur, POS = NOUN, TAG = NNS\n",
      ".: Head = feel, Lemma: ., Morph: PunctType=Peri, POS = PUNCT, TAG = .\n"
     ]
    }
   ],
   "source": [
    "text3 = (\"Although Julia is at least '19 year old', I feel like she has lived a million lives.\")\n",
    "doc3 = nlp(text3)\n",
    "for token in doc3: \n",
    "    print(f\"{token.text}: Head = {token.head}, Lemma: {token.lemma_}, Morph: {token.morph}, POS = {token.pos_}, TAG = {token.tag_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Julia: GPE (Countries, cities, states)\n",
      "at least '19 year old': DATE (Absolute or relative dates or periods)\n",
      "a million: CARDINAL (Numerals that do not fall under another type)\n"
     ]
    }
   ],
   "source": [
    "for ent in doc3.ents:\n",
    "    print(f\"{ent.text}: {ent.label_} ({spacy.explain(ent.label_)})\") # prints proper nouns/specific entities within the text and what sort of entity they are"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First version of sentence: \"Although I am only 19 years old, I feel like I have lived a million lives.\"\n",
    "\n",
    "The heads for each token had some very interesting results, likely because of the complex structure with \"although.\" For example, the head for the token \"am\" was \"feel\" which is in the next clause. \n",
    "\n",
    "The .lemma_ attribute did not provide as unexpected results, it simply returned the base of the word. Similarly, the POS tagging was very accurate, and the POS aligned with the TAG very consistently. \n",
    "\n",
    "The entity results were somewhat uunexpected. It made sense that it would return the two numbers, million and 19 years, but I was confused that it considered \"only 19 years old.\" The word only as a qualifier generally does not seem to be understood by the nlp. Also, although this number is used as an age, the nlp believed it to be a date. \n",
    "\n",
    "When making small changes, such as typos with extra letters or removing one letter, the individual words were still generally understood. For example, I deleted the letter \"a\" in the word \"am,\" and the nlp still deteced that it was meant to be a verb when looking at the POS tagging. What changed more substantially was the .head attribute results, because although it could tell that m was a verb, the overall sentence was not understood. \n",
    "\n",
    "I also changed \"I\" to my name \"Julia\" and spoke in the third person. I thought when checking for the entities, it would return as a person like \"Barack Obama.\" However, the nlp thought \"Julia\" was a GPE entity, that is a country, city, or state. \n",
    "\n",
    "I changed the word \"only\" to \"at least,\" to see if that is better understood by the nlp. However, once again the was no morphological information for the word \"at.\" This surprises me because words like \"only\" and \"at\" have many applications in the english language. \n",
    "\n",
    "Finally, I added quotation marks around '19 years old,' as if the speaker is quotting what \"Julia\" had said her age was, to see how this punctuation change impacted the spaCy pipeline. Interestingly, it regarded the quotation marks essentially as numbers, including them in the entity return. However, the quotation mark following the number was still understood as punctuation. \n",
    "\n",
    "Overall, the entities did not change much, just including the typos when adjusted. However, nonspecific names (i.e. names of people who are not famous/with no last name) are sometimes understood as GPEs. The tags did not often change but when they did it was because the typo or adjustment fundamentally changed the structure/meaning of the word. Although the changes were not always correct, the changes in result indicated that the nlp detected a change in meaning."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
